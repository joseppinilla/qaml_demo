{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Required packages\n",
        "import qaml\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision.datasets as torch_datasets\n",
        "import torchvision.transforms as torch_transforms\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################# Hyperparameters ##############################\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 64\n",
        "# Stochastic Gradient Descent\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 1e-4\n",
        "momentum = 0.5\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################### Input Data ################################\n",
        "train_dataset = torch_datasets.MNIST(root='./data/', train=True,\n",
        "                                     transform=torch_transforms.ToTensor(),\n",
        "                                     target_transform=torch_transforms.Compose([\n",
        "                                     lambda x:torch.LongTensor([x]),\n",
        "                                     lambda x:torch.nn.functional.one_hot(x,10)]),\n",
        "                                     download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_dataset = torch_datasets.MNIST(root='./data/', train=False,\n",
        "                                    transform=torch_transforms.ToTensor(),\n",
        "                                    target_transform=torch_transforms.Compose([\n",
        "                                    lambda x:torch.LongTensor([x]),\n",
        "                                    lambda x:torch.nn.functional.one_hot(x,10)]),\n",
        "                                    download=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################# Model Definition #############################\n",
        "DATA_SIZE = len(train_dataset.data[0].flatten())\n",
        "LABEL_SIZE = len(train_dataset.classes)\n",
        "\n",
        "VISIBLE_SIZE = DATA_SIZE + LABEL_SIZE\n",
        "HIDDEN_SIZE = 128\n",
        "\n",
        "# Specify model with dimensions\n",
        "rbm = qaml.nn.RBM(VISIBLE_SIZE, HIDDEN_SIZE)\n",
        "\n",
        "# Set up optimizer\n",
        "optimizer = torch.optim.SGD(rbm.parameters(), lr=learning_rate,\n",
        "                                              weight_decay=weight_decay,\n",
        "                                              momentum=momentum)\n",
        "# Set up training mechanisms\n",
        "sampler = qaml.sampler.GibbsNetworkSampler(rbm)\n",
        "CD = qaml.autograd.ConstrastiveDivergence()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################## Model Training ##############################\n",
        "# Set the model to training mode\n",
        "rbm.train()\n",
        "err_log = []\n",
        "for t in range(EPOCHS):\n",
        "    epoch_error = torch.Tensor([0.])\n",
        "    for img_batch, labels_batch in train_loader:\n",
        "\n",
        "        input_data = torch.cat((img_batch.flatten(1),labels_batch.flatten(1)),1)\n",
        "\n",
        "        # Positive Phase\n",
        "        v0, prob_h0 = input_data, rbm(input_data)\n",
        "        # Negative Phase\n",
        "        vk, prob_hk = sampler(v0, k=2)\n",
        "\n",
        "        # Reconstruction error from Contrastive Divergence\n",
        "        err = CD.apply((v0,prob_h0), (vk,prob_hk), *rbm.parameters())\n",
        "\n",
        "        # Do not accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Compute gradients. Save compute graph at last epoch\n",
        "        err.backward(retain_graph=(t == EPOCHS-1))\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "        epoch_error  += err\n",
        "    err_log.append(epoch_error.item())\n",
        "    print(f\"Epoch {t} Reconstruction Error = {epoch_error.item()}\")\n",
        "\n",
        "plt.plot(err_log)\n",
        "plt.ylabel(\"Reconstruction Error\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "rbm.eval()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################# VISUALIZE ####################################\n",
        "# Computation Graph\n",
        "from torchviz import make_dot\n",
        "make_dot(err)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option to save for future use\n",
        "torch.save(rbm,\"mnist_unsupervised.pt\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option to load existing model\n",
        "rbm = torch.load(\"mnist_unsupervised.pt\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################# ANIMATION ####################################\n",
        "from matplotlib.animation import FuncAnimation\n",
        "img = torch.zeros(1,DATA_SIZE)\n",
        "clamp = torch.nn.functional.one_hot(torch.LongTensor([3]),10)\n",
        "img_data = []\n",
        "for _ in range(1000):\n",
        "    prob_hk = rbm.forward(torch.cat((img,clamp),dim=1).bernoulli())\n",
        "    img,label = rbm.generate(prob_hk).split((DATA_SIZE,LABEL_SIZE),dim=1)\n",
        "    img_data.append(img.detach().clone().view(28,28).numpy())\n",
        "\n",
        "fig = plt.figure()\n",
        "plot = plt.matshow(img_data[0],fignum=0)\n",
        "def init():\n",
        "    plot.set_data(img_data[0])\n",
        "    return [plot]\n",
        "\n",
        "def update(j):\n",
        "    plot.set_data(img_data[j])\n",
        "    return [plot]\n",
        "\n",
        "anim = FuncAnimation(fig,update,init_func=init,frames=1000,interval=20,blit=True)\n",
        "plt.show()\n",
        "anim.save(\"./animation.gif\",\"pillow\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################## CLASSIFICATION ##################################\n",
        "count = 0\n",
        "for test_data, test_label in test_loader:\n",
        "    prob_hk = rbm.forward(torch.cat((test_data.flatten(1),torch.zeros(1,LABEL_SIZE)),dim=1))\n",
        "    _,label_pred = rbm.generate(prob_hk).split((DATA_SIZE,LABEL_SIZE),dim=1)\n",
        "    if label_pred.argmax() == test_label.argmax():\n",
        "        count+=1\n",
        "\n",
        "print(f\"Testing accuracy: {count}/{len(test_dataset)}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 0
}